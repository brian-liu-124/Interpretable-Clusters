{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sc\n",
    "import sklearn \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Build Random Forest and Return Tree Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_depths(tree1):\n",
    "    def get_node_depths_(current_node, current_depth, l, r, depths):\n",
    "        depths += [current_depth]\n",
    "        if l[current_node] != -1 and r[current_node] != -1:\n",
    "            get_node_depths_(l[current_node], current_depth + 1, l, r, depths)\n",
    "            get_node_depths_(r[current_node], current_depth + 1, l, r, depths)\n",
    "    depths = []\n",
    "    get_node_depths_(0, 0, tree1.tree_.children_left, tree1.tree_.children_right, depths) \n",
    "    return np.array(depths)\n",
    "\n",
    "def get_shared_nodes(i1,i2,node_indicator,n_nodes):\n",
    "    sample_ids = [i1, i2]\n",
    "    common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==\n",
    "                    len(sample_ids))\n",
    "    \n",
    "    common_node_id = np.arange(n_nodes)[common_nodes]\n",
    "    \n",
    "    return common_node_id\n",
    "\n",
    "# Tree distance between nodes n1, n2 = depth(n1) + depth(n2) - 2 depth(LCA)\n",
    "def distance_between_samples(indexes,depths,leaves,node_indicator,n_nodes):\n",
    "    i1 = indexes[0]\n",
    "    i2 = indexes[1]\n",
    "    leaf_node1 = leaves[i1]\n",
    "    leaf_node2 = leaves[i2]\n",
    "    depth_node1 = depths[leaf_node1]\n",
    "    depth_node2 = depths[leaf_node2]\n",
    "    ancestors = get_shared_nodes(i1,i2,node_indicator,n_nodes)\n",
    "    depth_LCA = max(depths[ancestors])\n",
    "    \n",
    "    dist = depth_node1 + depth_node2 - 2*depth_LCA\n",
    "    \n",
    "    return dist\n",
    "\n",
    "# bootstraps data and builds a tree, then calculates pairwise distances on the data instances relative to the tree\n",
    "# Tree distance is calculated via lowest common ancestor\n",
    "def build_tree(xTrain,yTrain,xTest,X):\n",
    "    train = xTrain.copy()\n",
    "    train['y'] = yTrain\n",
    "    train1 = train.sample(n = len(train), replace = True) \n",
    "    yTrain1 = train1['y']\n",
    "    xTrain1 = train1.drop('y',axis = 1)\n",
    "    gc.collect()\n",
    "    estimator = DecisionTreeClassifier().fit(xTrain1,yTrain1)\n",
    "    n_nodes = estimator.tree_.node_count\n",
    "    depths = get_node_depths(estimator)\n",
    "    leaves_train = estimator.apply(xTrain)\n",
    "    leaves_test = estimator.apply(xTest)\n",
    "    node_indicator_test = estimator.decision_path(xTest)\n",
    "    node_indicator_train = estimator.decision_path(xTrain)\n",
    "    train_comb = list(itertools.combinations(range(0,len(xTrain)), 2))\n",
    "    test_comb = list(itertools.combinations(range(0,len(xTest)), 2))\n",
    "\n",
    "    ### Train Distances\n",
    "    train_distances = []\n",
    "    for indexes in train_comb:\n",
    "        dist = distance_between_samples(indexes,depths,leaves_train,node_indicator_train,n_nodes)\n",
    "        train_distances.append([indexes[0],indexes[1],dist])\n",
    "\n",
    "    ### Test Distances\n",
    "    test_distances = []\n",
    "    for indexes in test_comb:\n",
    "        dist = distance_between_samples(indexes,depths,leaves_test,node_indicator_test,n_nodes)\n",
    "        test_distances.append([indexes[0],indexes[1],dist])\n",
    "\n",
    "    train_dist_df = pd.DataFrame(train_distances, columns = ['i1','i2','tree_dist'])\n",
    "    test_dist_df = pd.DataFrame(test_distances, columns = ['i1','i2','tree_dist'])\n",
    "    \n",
    "    leaves_all = estimator.apply(X)\n",
    "    node_indicator_all = estimator.decision_path(X)\n",
    "    dist_args = [depths,leaves_all,node_indicator_all,n_nodes]\n",
    "    \n",
    "    return([estimator,train_dist_df,test_dist_df,dist_args])\n",
    "\n",
    "def fit_random_forest(xTrain,yTrain,num_trees,xTest,X):\n",
    "    i = 0\n",
    "    mods = []\n",
    "    dist_args = []\n",
    "    train_dists = pd.DataFrame()\n",
    "    test_dists = pd.DataFrame()\n",
    "    while i <= num_trees:\n",
    "        tree = build_tree(xTrain,yTrain,xTest,X)\n",
    "        mods.append(tree[0])\n",
    "        train_dists = train_dists.append(tree[1])\n",
    "        test_dists = test_dists.append(tree[2])\n",
    "        dist_args.append(tree[3])\n",
    "        i = i+1\n",
    "    train_final_dist = train_dists.groupby(['i1','i2']).mean().reset_index()\n",
    "    test_final_dist = test_dists.groupby(['i1','i2']).mean().reset_index()\n",
    "    return(mods,train_final_dist,test_final_dist,dist_args)\n",
    "\n",
    "def rf_predict(xTest,mods):\n",
    "    pred = []\n",
    "    for clf in mods:\n",
    "        pred.append(clf.predict(xTest))\n",
    "    pred = np.mean(pred,axis = 0)\n",
    "    pred = [int(x) for x in pred>=0.5]\n",
    "    return pred\n",
    "\n",
    "def return_distance_matrix(xTrain,yTrain,num_trees,xTest,X):\n",
    "    mods,train_final_dist,test_final_dist,dist_args = fit_random_forest(xTrain,yTrain,num_trees,xTest,X)\n",
    "    train_final_dist = train_final_dist.groupby(['i1','i2']).mean().reset_index()\n",
    "    test_final_dist = test_final_dist.groupby(['i1','i2']).mean().reset_index()\n",
    "    test_final_dist1 = test_final_dist.copy()\n",
    "    test_final_dist1['i1'] = test_final_dist['i2']\n",
    "    test_final_dist1['i2'] = test_final_dist['i1']\n",
    "    test_final_dist = test_final_dist.append(test_final_dist1)\n",
    "    \n",
    "    test_dist = np.zeros(shape = (max(test_final_dist['i1'])+1,max(test_final_dist['i1'])+1))\n",
    "    for i in range(0,len(test_final_dist)):\n",
    "        temp = test_final_dist.iloc[i]\n",
    "        i1 = int(temp['i1'])\n",
    "        i2 = int(temp['i2'])\n",
    "        tree_dist = temp['tree_dist']\n",
    "        test_dist[i1][i2] = tree_dist\n",
    "\n",
    "    train_final_dist1 = train_final_dist.copy()\n",
    "    train_final_dist1['i1'] = train_final_dist['i2']\n",
    "    train_final_dist1['i2'] = train_final_dist['i1']\n",
    "    train_final_dist = train_final_dist.append(train_final_dist1)\n",
    "    train_dist = np.zeros(shape = (max(train_final_dist['i1'])+1,max(train_final_dist['i1'])+1))\n",
    "    for i in range(0,len(train_final_dist)):\n",
    "        temp = train_final_dist.iloc[i]\n",
    "        i1 = int(temp['i1'])\n",
    "        i2 = int(temp['i2'])\n",
    "        tree_dist = temp['tree_dist']\n",
    "        train_dist[i1][i2] = tree_dist\n",
    "    \n",
    "    return mod, test_dist, dist_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
